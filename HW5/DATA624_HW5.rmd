---
title: 'DATA624: Homework 5'
author: "Eric Lehmphul"
date: "2/28/2023"
output: 
  rmdformats::readthedown:
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(fpp3)
```


# Task

Do exercises 8.1, 8.5, 8.6, 8.7, 8.8, 8.9  in Hyndman.  Please submit both the link to your Rpubs and the .rmd file.


# Exercises


## 8.1


Consider the the number of pigs slaughtered in Victoria, available in the aus_livestock dataset.

a. Use the ETS() function to estimate the equivalent model for simple exponential smoothing. Find the optimal values of  alpha and level 0, and generate forecasts for the next four months.

b. Compute a 95% prediction interval for the first forecast using y +/- 1.96s where s is the standard deviation of the residuals. Compare your interval with the interval produced by R.

### Part A

The alpha is 0.322 and the level 0 is 100647. The 4 month forecast is below. 

```{r}
victoria.pigs <- aus_livestock %>%
  filter(State == "Victoria", Animal == "Pigs")

fit <- victoria.pigs %>%
  model(M1 = ETS(Count ~ error("A") + trend("N") + season("N")))


fc <- fit %>%
  forecast(h = 4)
```


```{r}
fc %>%
autoplot(victoria.pigs)
```


```{r}
fit %>% coef()
```


### Part B

* Calculated Prediction Interval: [76854.452, 113518.663]
* Predicted Prediction Interval:[76854.7889, 113518.32597]

```{r}
report(fit)
```


```{r}
sd <- sqrt(87480760)

upper <- round(fc$.mean[1] + 1.96 * sd, 3)
lower <- round(fc$.mean[1] - 1.96 * sd, 3)

model.ci <- fc %>% hilo(95) %>% pull('95%') %>% head(1)
```

```{r}
paste0("Calculated Prediction Interval: [", lower, ", ", upper, "]")
paste0("Predicted Prediction Interval:", model.ci)
```


## 8.5

Data set global_economy contains the annual Exports from many countries. Select one country to analyse.

a. Plot the Exports series and discuss the main features of the data.

b. Use an ETS(A,N,N) model to forecast the series, and plot the forecasts.

c. Compute the RMSE values for the training data.

d. Compare the results to those from an ETS(A,A,N) model. (Remember that the trended model is using one more parameter than the simpler model.) Discuss the merits of the two forecasting methods for this data set.

e. Compare the forecasts from both methods. Which do you think is best?

f. Calculate a 95% prediction interval for the first forecast for each model, using the RMSE values and assuming normal errors. Compare your intervals with those produced using R.

### Part A

The US exports have an upward trend from 1960 to 2016. Notable drops in exports during the 1980s and late 2000s, reflecting a recession occurred.

```{r}
us.econ <- global_economy %>%
  filter(Country == "United States")

us.econ <- us.econ[-58,]

autoplot(us.econ, Exports)
```



### Part B

```{r}
fit <- us.econ %>%
  model(PartB = ETS(Exports ~ error("A") + trend("N") + season("N")))


fc <- fit %>%
  forecast(h = 4)


fc %>%
autoplot(us.econ) +
  ggtitle("ETS(A, N, N) Forecast")
```

### Part C

The RMSE is 0.627 for the model.

```{r}
accuracy(fit)
```

### Part D

The RMS for the ETS(A, A, N) is slightly better than that of the ETS(A, N, N) model. Generally, simple exponential smoothing (ETS(A, N, N)) is a better fitting model when the data has no clear trend or seasonal pattern. The  Holt's Linear Trend method (ETS(A, A, N)) contains another optimizable equation to account for trends in the data. Therefore the ETS(A, A, N) model is preferred.

```{r}
fit2 <- us.econ %>%
  model(PartD = ETS(Exports ~ error("A") + trend("A") + season("N")))


fc2 <- fit2 %>%
  forecast(h = 4)


fc2 %>%
autoplot(us.econ) +
  ggtitle("ETS(A, A, N) Forecast")
```


```{r}
rbind(data.frame(accuracy(fit)), data.frame(accuracy(fit2)))
```

### Part E

As mentioned above, the model created in part D accounts for the trend in the data. US exports appear to be trending upward, therefore I would select the ETS(A, A, N) model for this timeseries.  

```{r}
fit3 <- us.econ %>%
  model(PartB = ETS(Exports ~ error("A") + trend("N") + season("N")),
        PartD = ETS(Exports ~ error("A") + trend("A") + season("N")))


fc3 <- fit3 %>%
  forecast(h = 4)


fc3 %>%
autoplot(us.econ) +
  ggtitle("Part B and Part D Forecast Comparison")
```

### Part F

The calculated prediction intervals for both models are very similar to the one produced in R. 

* Part B: Calculated Prediction Interval: [10.639, 13.142]
* Part B: Predicted Prediction Interval:[10.6395079134527, 13.1418592559602]
* Part D: Calculated Prediction Interval: [10.757, 13.257]
* Part D: Predicted Prediction Interval:[10.7566652294566, 13.2565616708691]

```{r}
glance(fit3)
```


```{r}
sd <- sqrt(0.4075120)

upper <- round(fc$.mean[1] + 1.96 * sd, 3)
lower <- round(fc$.mean[1] - 1.96 * sd, 3)

model.ci <- fc %>% hilo(95) %>% pull('95%') %>% head(1)
```

```{r}
sd2 <- sqrt(0.4067128)

upper2 <- round(fc2$.mean[1] + 1.96 * sd2, 3)
lower2 <- round(fc2$.mean[1] - 1.96 * sd2, 3)

model.ci2 <- fc2 %>% hilo(95) %>% pull('95%') %>% head(1)
```

```{r}
paste0("Part B: Calculated Prediction Interval: [", lower, ", ", upper, "]")
paste0("Part B: Predicted Prediction Interval:", model.ci)
```


```{r}
paste0("Part D: Calculated Prediction Interval: [", lower2, ", ", upper2, "]")
paste0("Part D: Predicted Prediction Interval:", model.ci2)
```




## 8.6

Forecast the Chinese GDP from the global_economy data set using an ETS model. Experiment with the various options in the ETS() function to see how much the forecasts change with damped trend, or with a Box-Cox transformation. Try to develop an intuition of what each is doing to the forecasts.

[Hint: use a relatively large value of h when forecasting, so you can clearly see the differences between the various options when plotting the forecasts.]


* Alpha effects the level of the forecast. Low alpha means more weight is applied to older observations. High alpha means that more weight is given to newer observations
* Beta effects the slope of the forecast. Low beta means more weight is applied to older observations. High beta means that more weight is given to newer observations
* Phi effects the severity of the damping effect. Low phi caues the damping effect to occur sooner. High phi pushes the damping effect further into the future.
* Boxcox seems to provide an exponential forecast that is much higher than the other methods.

```{r}
alpha = 0.1
beta = 0.1
phi = 0.1



china.data <- global_economy %>%
  filter(Country == "China")

lambda <- china.data %>%
  features(GDP, features = guerrero) %>%
  pull(lambda_guerrero)



fit1 <- china.data %>%
  model(`Simple Exponential Smoothing` = ETS(GDP ~ error("A") + trend("N", alpha = alpha) + season("N")),
        `Holts method` = ETS(GDP ~ error("A") + trend("A", alpha = alpha, beta = beta) + season("N")),
        `Damped Holt's method` = ETS(GDP ~ error("A") + trend("Ad", alpha = alpha, beta = beta, phi = phi) + season("N")),
        `Box Cox` = ETS(box_cox(GDP,lambda) ~ error("A") + trend("A", alpha = alpha, beta = beta) + season("N")),
        `Damped Box Cox` = ETS(box_cox(GDP,lambda) ~ error("A") + trend("Ad", alpha = alpha, beta = beta, phi = phi) + season("N"))) %>%
  forecast(h = 10) %>%
  autoplot(china.data) +
  ggtitle("China Data")


fit1
```




```{r}
alpha = 0.5
beta = 0.5
phi = 0.5



china.data <- global_economy %>%
  filter(Country == "China")

lambda <- china.data %>%
  features(GDP, features = guerrero) %>%
  pull(lambda_guerrero)



fit2 <- china.data %>%
  model(`Simple Exponential Smoothing` = ETS(GDP ~ error("A") + trend("N", alpha = alpha) + season("N")),
        `Holts method` = ETS(GDP ~ error("A") + trend("A", alpha = alpha, beta = beta) + season("N")),
        `Damped Holt's method` = ETS(GDP ~ error("A") + trend("Ad", alpha = alpha, beta = beta, phi = phi) + season("N")),
        `Box Cox` = ETS(box_cox(GDP,lambda) ~ error("A") + trend("A", alpha = alpha, beta = beta) + season("N")),
        `Damped Box Cox` = ETS(box_cox(GDP,lambda) ~ error("A") + trend("Ad", alpha = alpha, beta = beta, phi = phi) + season("N"))) %>%
  forecast(h = 10) %>%
  autoplot(china.data) +
  ggtitle("China Data")


fit2
```



```{r}
alpha = 0.9
beta = 0.9
phi = 0.9



china.data <- global_economy %>%
  filter(Country == "China")

lambda <- china.data %>%
  features(GDP, features = guerrero) %>%
  pull(lambda_guerrero)


fit3 <- china.data %>%
  model(`Simple Exponential Smoothing` = ETS(GDP ~ error("A") + trend("N", alpha = alpha) + season("N")),
        `Holts method` = ETS(GDP ~ error("A") + trend("A", alpha = alpha, beta = beta) + season("N")),
        `Damped Holt's method` = ETS(GDP ~ error("A") + trend("Ad", alpha = alpha, beta = beta, phi = phi) + season("N")),
        `Box Cox` = ETS(box_cox(GDP,lambda) ~ error("A") + trend("A", alpha = alpha, beta = beta) + season("N")),
        `Damped Box Cox` = ETS(box_cox(GDP,lambda) ~ error("A") + trend("Ad", alpha = alpha, beta = beta, phi = phi) + season("N"))) %>%
  forecast(h = 10) %>%
  autoplot(china.data) +
  ggtitle("China Data")


fit3
```




## 8.7


Find an ETS model for the Gas data from aus_production and forecast the next few years. Why is multiplicative seasonality necessary here? Experiment with making the trend damped. Does it improve the forecasts?

Multiplicative seasonality is necessary because the seasonality increases as over time. Additive would be preferred if the seasonality variability was fairly constant quarter after quarter. Both the Multiplicative and Damped Multiplicative models performed almost identical based on the plot and accuracy metrics. I would say that the damped effec does not improve the forecasts within the next few years.


```{r}
aus_production <- aus_production


fit <- aus_production %>%
  model(Multiplicative = ETS(Gas ~ error("M") + trend("A") + season("M")),
        `Damped Multiplicative` = ETS(Gas ~ error("M") + trend("Ad") + season("M")))


fc <- fit %>%
  forecast(h = 16)
```


```{r}
fc %>%
autoplot(aus_production)
```


```{r}
data.frame(accuracy(fit))
```


## 8.8


Recall your retail time series data (from Exercise 8 in Section 2.10).

a. Why is multiplicative seasonality necessary for this series?

b. Apply Holt-Winters’ multiplicative method to the data. Experiment with making the trend damped.

c. Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?

d. Check that the residuals from the best method look like white noise.

e. Now find the test set RMSE, while training the model to the end of 2010. Can you beat the seasonal naïve approach from Exercise 7 in Section 5.11?



### Part A

The variation in the seasonality changes over time, therefore a multiplicative seasonality component is preferred.

```{r}
set.seed(15)

myseries <- aus_retail %>%
  filter(`Series ID` == sample(aus_retail$`Series ID`,1))

autoplot(myseries, Turnover)
```



### Part B

The damped method appears to provide consistently lower projections than its non-damped counterpart model.

```{r}
fit <- myseries %>%
  model(`Holt Winters Multiplicative` = ETS(Turnover ~ error("M") + trend("A") + season("M")),
        `Damped Multiplicative` = ETS(Turnover ~ error("M") + trend("Ad") + season("M")))


fc <- fit %>%
  forecast(h = 20)

fc %>%
  autoplot(myseries)
```




### Part C

The Damped Multiplicative model has a lowest RMSE, therefore it fits the training data the best. I would prefer using the Damped Multiplicative model as it appears to be a better fit for the timeseries.

```{r}
accuracy(fit)
```



### Part D

The innovation residuals plot shows many spikes in the data, meaning that the residual variance fluctuates. Many lags are outside the blue interval, pointing toward autocorrelation. The histogram appears to be near normal wih a handful of outliers on each side of the mean. The statistical tests run below both reject the null hypothesis (pvalue < 0.05), indicating the possibility of non-zero autocorrelation within the first 24 lags. The residuals appear to not b white noise, indicating that there is most likely a more superior model to use to forecast this data.

```{r}
fit <- myseries %>%
  model(`Damped Multiplicative` = ETS(Turnover ~ error("M") + trend("Ad") + season("M")))

fit %>%
  gg_tsresiduals()
```

```{r}
myseries %>% features(Turnover, box_pierce, lag = 24)

myseries %>% features(Turnover, ljung_box, lag = 24)
```



### Part E

Both exponential smoothing approaches produced a better forecast than the naive approach. The Damped Multiplicative model was only a slightly better fit than the naive method, whereas the Holts-Winters Multiplicative model performed the best by far on the test data.

```{r}
train.data <- myseries %>%
  filter(year(Month) <= 2010)

test.data <- myseries %>%
  filter(year(Month) > 2010)

fit <- train.data %>%
  model(`Holt Winters Multiplicative` = ETS(Turnover ~ error("M") + trend("A") + season("M")),
        `Damped Multiplicative` = ETS(Turnover ~ error("M") + trend("Ad") + season("M")),
        `Seasonal Naive` = SNAIVE(Turnover))

fc <- fit %>%
  forecast(test.data)


fc %>%
  autoplot(myseries, level = NULL)


fc %>% accuracy(test.data)
```


## 8.9


For the same retail data, try an STL decomposition applied to the Box-Cox transformed series, followed by ETS on the seasonally adjusted data. How does that compare with your best previous forecasts on the test set?


I was unable to successfully compare the test set results from the STL model to the other models, instead I will compare the training set results. The STL decomposition provided the best RMSE out of all of the models. The both boxcox transformation models were more effective than the non-transformed model. A combination of model complexity and data manipulation is most likely to produce an optimal forecasting result. It should be noted that boxcox transformation effects the readability of the model results, making it less practical in certain situations. It is interesting to view the forecast vs the actual timeseries for the test data. The best fit given the train data is the simple boxcox though the true best model is the complex boxcox model.

```{r}
lambda <- train.data %>%
  features(Turnover, features = guerrero) %>%
  pull(lambda_guerrero)

stl.model <- train.data %>%
model(`STL Boxcox` = STL(box_cox(Turnover, lambda)))

fit <- train.data %>%
  model(`Simple ETS Boxcox` =ETS(box_cox(Turnover, lambda)),
        `Complex ETS Boxcox` =ETS(box_cox(Turnover, lambda) ~ error("M") + trend("A") + season("M")),
        `Non Transformed Holt Winters Multiplicative` = ETS(Turnover ~ error("M") + trend("A") + season("M")))
```


```{r}
stl.model %>%
  components() %>%
  autoplot()
```


```{r}
fc <- fit %>%
  forecast(test.data)


fc %>%
  autoplot(myseries, level = NULL)
```


```{r}
rbind(accuracy(stl.model), accuracy(fit))
```

Error received when trying to get test data forecasting for stl model. 

```{r, error=TRUE}
fc <- stl.model %>%
  forecast(test.data)
```





